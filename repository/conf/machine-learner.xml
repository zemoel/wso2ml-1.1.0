<?xml version="1.0" encoding="UTF-8"?>
<MachineLearner>
	<!-- JNDI name of the data source to be used by the Machine Learner. This 
		data source should be defined in the master-datasources.xml file in conf/datasources 
		directory. -->
	<DataSourceName>jdbc/WSO2ML_DB</DataSourceName>

	<!-- Configurations to calculate summary statistics from a dataset. histogramBins 
		: Number of intervals in a histogram. categoricalThreshold : threshold to
		determine whether a given feature is categorical or numerical based on the
		skewness of the distribution. sampleSize : Size of the dataset sample which
		will be used for summary statistics calculation and visualization. -->
	<SummaryStatisticsSettings>
		<HistogramBins>20</HistogramBins>
		<CategoricalThreshold>80</CategoricalThreshold>
		<SampleSize>10000</SampleSize>
	</SummaryStatisticsSettings>

	<!-- Properties used by WSO2 ML -->
	<Properties>
		<!-- Defines the size of the thread pool used in WSO2 ML. -->
		<Property name="ml.thread.pool.size" value="100" />
		<!-- Defines the size of the blocked queue used by the thread pool of WSO2 ML. -->
		<Property name="ml.thread.pool.queue.size" value="1000" />
		<!-- Fully qualified name of the file input adapter to be used. -->
		<Property name="file.in"
				  value="org.wso2.carbon.ml.core.impl.FileInputAdapter" />
		<!-- Fully qualified name of the file output adapter to be used. -->
		<Property name="file.out"
				  value="org.wso2.carbon.ml.core.impl.FileOutputAdapter" />
		<!-- Fully qualified name of the HDFS input adapter to be used. -->
		<Property name="hdfs.in"
				  value="org.wso2.carbon.ml.core.impl.HdfsInputAdapter" />
		<!-- Fully qualified name of the HDFS output adapter to be used. -->
		<Property name="hdfs.out"
				  value="org.wso2.carbon.ml.core.impl.HdfsOutputAdapter" />
		<!-- Fully qualified name of the Registry input adapter to be used. -->
		<Property name="registry.in"
				  value="org.wso2.carbon.ml.core.impl.RegistryInputAdapter" />
		<!-- Fully qualified name of the Registry output adapter to be used. -->
		<Property name="registry.out"
				  value="org.wso2.carbon.ml.core.impl.RegistryOutputAdapter" />
	</Properties>

	<!-- Comma separated set of email addresses to which the model building status mails are sent. -->
	<EmailNotificationEndpoint></EmailNotificationEndpoint>

	<!-- Governance Registry location where ML models are published. -->
	<ModelRegistryLocation>ml</ModelRegistryLocation>

	<!-- Optional element. This element should point to a HDFS location where 
		ML is allowed to store files. -->
	<HdfsURL>hdfs://localhost:9000</HdfsURL>

	<!-- Storage Details for uploaded datasets. StorageType can be either "file" 
		or "hdfs". Default storage type is file and location is {carbon.home}/datasets -->
	<!-- DatasetStorage> 
		<StorageType>file</StorageType> 
		<StorageDirectory>/tmp</StorageDirectory> 
	</DatasetStorage -->

	<!-- Storage Details for built ML Models. StorageType can be either "file" 
		or "hdfs". Default storage type is file and location is {carbon.home}/models -->
	<!-- ModelStorage> 
		<StorageType>file</StorageType> 
		<StorageDirectory>/tmp</StorageDirectory> 
	</ModelStorage -->

	<!-- Lists all supported machine learning algorithms. -->
	<Algorithms>
		<Algorithm>
			<Name>LINEAR_REGRESSION</Name>
			<Type>Numerical_Prediction</Type>
			<isPMMLExportable>true</isPMMLExportable>
			<Parameters>
				<Name>Iterations</Name>
				<Value>100</Value>
				<Description>Number of times optimizer runs before completing the
					optimization process. This parameter value should be an integer
					greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Learning_Rate</Name>
				<Value>0.001</Value>
				<Description>Step size of the optimization algorithm. This parameter
					value should be between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
			<Parameters>
				<Name>SGD_Data_Fraction</Name>
				<Value>1</Value>
				<Description>Fraction of the training dataset used per iteration
					in the optimization algorithm. This parameter value should be
					between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>RIDGE_REGRESSION</Name>
			<Type>Numerical_Prediction</Type>
			<isPMMLExportable>true</isPMMLExportable>
			<Parameters>
				<Name>Iterations</Name>
				<Value>100</Value>
				<Description>Number of times optimizer runs before completing the
					optimization process. This parameter value should be an integer
					greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Learning_Rate</Name>
				<Value>0.001</Value>
				<Description>Step size of the optimization algorithm. This parameter
					value should be between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Reg_Parameter</Name>
				<Value>0.001</Value>
				<Description>The regularization parameter (also lambda) reduces overfitting
					which reduces the variance of your estimated regression parameters. It
					does this at the expense of adding bias to your estimate. Increasing
					this value results less overfitting but also greater bias. This parameter
					value should be a non-negative real number (0 inclusive).
				</Description>
			</Parameters>
			<Parameters>
				<Name>SGD_Data_Fraction</Name>
				<Value>1</Value>
				<Description>Fraction of the training dataset used per iteration
					in the optimization algorithm. This parameter value should be
					between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>LASSO_REGRESSION</Name>
			<Type>Numerical_Prediction</Type>
			<isPMMLExportable>true</isPMMLExportable>
			<Parameters>
				<Name>Iterations</Name>
				<Value>100</Value>
				<Description>Number of times optimizer runs before completing the
					optimization process. This parameter value should be an integer
					greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Learning_Rate</Name>
				<Value>0.001</Value>
				<Description>Step size of the optimization algorithm. This parameter
					value should be between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Reg_Parameter</Name>
				<Value>0.001</Value>
				<Description>The regularization parameter (also lambda) reduces overfitting
					which reduces the variance of your estimated regression parameters. It
					does this at the expense of adding bias to your estimate. Increasing
					this value results less overfitting but also greater bias. This parameter
					value should be a non-negative real number (0 inclusive).
				</Description>
			</Parameters>
			<Parameters>
				<Name>SGD_Data_Fraction</Name>
				<Value>1</Value>
				<Description>Fraction of the training dataset used per iteration
					in the optimization algorithm. This parameter value should be
					between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>RANDOM_FOREST_REGRESSION</Name>
			<Type>Numerical_Prediction</Type>
			<isPMMLExportable>false</isPMMLExportable>
			<Parameters>
				<Name>Num_Trees</Name>
				<Value>5</Value>
				<Description>Number of trees in the random forest. Increasing the
					number of trees will decrease the variance in predictions,
					improving the modelâ€™s test-time accuracy. Also training time
					increases roughly linearly in the number of trees. This parameter
					value should be an integer greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Max_Depth</Name>
				<Value>5</Value>
				<Description>Maximum depth of the tree. This helps you to control
					the size of the tree to prevent overfitting. This parameter
					value should be an integer greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Max_Bins</Name>
				<Value>100</Value>
				<Description>Number of bins used when discretizing continuous
					features. This must be at least the maximum number of categories M
					for any categorical feature. Increasing this allows the algorithm
					to consider more split candidates and make fine-grained split
					decisions. However, it also increases computation and
					communication. This parameter value should be an integer greater
					than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Impurity</Name>
				<Value>variance</Value>
				<Description>Impurity is a measure of the homogeneity of
					the labels at the node. This parameter value should be 'variance'.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Feature_Subset_Strategy</Name>
				<Value>auto</Value>
				<Description>Number of features to use as candidates for splitting
					at each tree node. The number is specified as a fraction or
					function of the total number of features. Decreasing this number
					will speed up training, but can sometimes impact performance if too
					low. This parameter value can take values 'auto', 'all', 'sqrt',
					'log2' and 'onethird' (without quotes).
				</Description>
			</Parameters>
			<Parameters>
				<Name>Seed</Name>
				<Value>12345</Value>
				<Description>Seed for the random number generator.</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>LOGISTIC_REGRESSION</Name>
			<Type>Classification</Type>
			<isPMMLExportable>true</isPMMLExportable>
			<Parameters>
				<Name>Iterations</Name>
				<Value>100</Value>
				<Description>Number of times optimizer runs before completing the
					optimization process. This parameter value should be an integer
					greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Learning_Rate</Name>
				<Value>0.1</Value>
				<Description>Step size of the optimization algorithm. This parameter
					value should be between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Reg_Type</Name>
				<Value>L2</Value>
				<Description>Type of the regularization. This parameter value
					should be either 'L1' or 'L2' (without quotes).
				</Description>
			</Parameters>
			<Parameters>
				<Name>Reg_Parameter</Name>
				<Value>0.001</Value>
				<Description>The regularization parameter (also lambda) reduces overfitting
					which reduces the variance of your estimated regression parameters. It
					does this at the expense of adding bias to your estimate. Increasing
					this value results less overfitting but also greater bias. This parameter
					value should be a non-negative real number (0 inclusive).
				</Description>
			</Parameters>
			<Parameters>
				<Name>SGD_Data_Fraction</Name>
				<Value>1</Value>
				<Description>Fraction of the training dataset used per iteration
					in the optimization algorithm. This parameter value should be
					between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>LOGISTIC_REGRESSION_LBFGS</Name>
			<Type>Classification</Type>
			<isPMMLExportable>true</isPMMLExportable>
			<Parameters>
				<Name>Reg_Type</Name>
				<Value>L2</Value>
				<Description>Type of the regularization. This parameter value
					should be either 'L1' or 'L2' (without quotes).
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>SVM</Name>
			<Type>Classification</Type>
			<isPMMLExportable>true</isPMMLExportable>
			<Parameters>
				<Name>Iterations</Name>
				<Value>100</Value>
				<Description>Number of times optimizer runs before completing the
					optimization process. This parameter value should be an integer
					greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Learning_Rate</Name>
				<Value>0.001</Value>
				<Description>Step size of the optimization algorithm. This parameter
					value should be between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Reg_Type</Name>
				<Value>L1</Value>
				<Description>Type of the regularization. This parameter value
					should be either 'L1' or 'L2' (without quotes).
				</Description>
			</Parameters>
			<Parameters>
				<Name>Reg_Parameter</Name>
				<Value>0.001</Value>
				<Description>The regularization parameter (also lambda) reduces overfitting
					which reduces the variance of your estimated regression parameters. It
					does this at the expense of adding bias to your estimate. Increasing
					this value results less overfitting but also greater bias. This parameter
					value should be a non-negative real number (0 inclusive).
				</Description>
			</Parameters>
			<Parameters>
				<Name>SGD_Data_Fraction</Name>
				<Value>1</Value>
				<Description>Fraction of the training dataset used per iteration
					in the optimization algorithm. This parameter value should be
					between 0 and 1, 1 inclusive.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>DECISION_TREE</Name>
			<Type>Classification</Type>
			<isPMMLExportable>false</isPMMLExportable>
			<Parameters>
				<Name>Max_Depth</Name>
				<Value>5</Value>
				<Description>Maximum depth of the tree. This helps you to control
					the size of the tree to prevent overfitting. This parameter
					value should be an integer greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Max_Bins</Name>
				<Value>100</Value>
				<Description>Number of bins used when discretizing continuous
					features. This must be at least the maximum number of categories M
					for any categorical feature. Increasing this allows the algorithm
					to consider more split candidates and make fine-grained split
					decisions. However, it also increases computation and
					communication. This parameter value should be an integer greater
					than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Impurity</Name>
				<Value>gini</Value>
				<Description>Impurity is a measure of the homogeneity of
					the labels at the node. This parameter value should be either 'gini'
					or 'entropy' (without quotes).
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>RANDOM_FOREST_CLASSIFICATION</Name>
			<Type>Classification</Type>
			<isPMMLExportable>false</isPMMLExportable>
			<Parameters>
				<Name>Num_Trees</Name>
				<Value>5</Value>
				<Description>Number of trees in the random forest. Increasing the
					number of trees will decrease the variance in predictions,
					improving the modelâ€™s test-time accuracy. Also training time
					increases roughly linearly in the number of trees. This parameter
					value should be an integer greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Max_Depth</Name>
				<Value>5</Value>
				<Description>Maximum depth of the tree. This helps you to control
					the size of the tree to prevent overfitting. This parameter
					value should be an integer greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Max_Bins</Name>
				<Value>100</Value>
				<Description>Number of bins used when discretizing continuous
					features. This must be at least the maximum number of categories M
					for any categorical feature. Increasing this allows the algorithm
					to consider more split candidates and make fine-grained split
					decisions. However, it also increases computation and
					communication. This parameter value should be an integer greater
					than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Impurity</Name>
				<Value>gini</Value>
				<Description>Impurity is a measure of the homogeneity of
					the labels at the node. This parameter value should be either 'gini'
					or 'entropy' (without quotes).
				</Description>
			</Parameters>
			<Parameters>
				<Name>Feature_Subset_Strategy</Name>
				<Value>auto</Value>
				<Description>Number of features to use as candidates for splitting
					at each tree node. The number is specified as a fraction or
					function of the total number of features. Decreasing this number
					will speed up training, but can sometimes impact performance if too
					low. This parameter value can take values 'auto', 'all', 'sqrt',
					'log2' and 'onethird' (without quotes).
				</Description>
			</Parameters>
			<Parameters>
				<Name>Seed</Name>
				<Value>12345</Value>
				<Description>Seed for the random number generator.</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>NAIVE_BAYES</Name>
			<Type>Classification</Type>
			<isPMMLExportable>false</isPMMLExportable>
			<Parameters>
				<Name>Lambda</Name>
				<Value>1</Value>
				<Description>Additive smoothing can be used by setting this
					parameter. This parameter value should be an integer greater
					than 0.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>K_MEANS</Name>
			<Type>Clustering</Type>
			<isPMMLExportable>true</isPMMLExportable>
			<Parameters>
				<Name>Max_Iterations</Name>
				<Value>20</Value>
				<Description>Maximum number of times optimizer runs before completing the
					optimization process. This parameter value should be an integer
					greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Num_Clusters</Name>
				<Value>3</Value>
				<Description>The number of desired clusters. This value should be
					an integer greater than 0.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>K_MEANS_ANOMALY_DETECTION_WITH_UNLABELED_DATA</Name>
			<Type>Anomaly_Detection</Type>
			<isPMMLExportable>false</isPMMLExportable>
			<Parameters>
				<Name>Max_Iterations</Name>
				<Value>100</Value>
				<Description>Maximum number of times optimizer runs before completing the
					optimization process. This parameter value should be an integer
					greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Num_of_Normal_Clusters</Name>
				<Value>5</Value>
				<Description>The number of desired normal clusters. This value should be
					an integer greater than 0.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>K_MEANS_ANOMALY_DETECTION_WITH_LABELED_DATA</Name>
			<Type>Anomaly_Detection</Type>
			<isPMMLExportable>false</isPMMLExportable>
			<Parameters>
				<Name>Max_Iterations</Name>
				<Value>100</Value>
				<Description>Maximum number of times optimizer runs before completing the
					optimization process. This parameter value should be an integer
					greater than 0.
				</Description>
			</Parameters>
			<Parameters>
				<Name>Num_of_Normal_Clusters</Name>
				<Value>5</Value>
				<Description>The number of desired normal clusters. This value should be
					an integer greater than 0.
				</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>COLLABORATIVE_FILTERING</Name>
			<Type>Recommendation</Type>
			<Parameters>
				<Name>Rank</Name>
				<Value>8</Value>
				<Description>The number of latent factors in the model.</Description>
			</Parameters>
			<Parameters>
				<Name>Iterations</Name>
				<Value>20</Value>
				<Description>Number of iterations of ALS.</Description>
			</Parameters>
			<Parameters>
				<Name>Lambda</Name>
				<Value>0.01</Value>
				<Description>Regularization parameter in ALS.</Description>
			</Parameters>
			<Parameters>
				<Name>Blocks</Name>
				<Value>-1</Value>
				<Description>Level of Parallelism to split computation into. Set to -1 to auto-configure.</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>COLLABORATIVE_FILTERING_IMPLICIT</Name>
			<Type>Recommendation</Type>
			<Parameters>
				<Name>Rank</Name>
				<Value>8</Value>
				<Description>The number of latent factors in the model.</Description>
			</Parameters>
			<Parameters>
				<Name>Iterations</Name>
				<Value>20</Value>
				<Description>Number of iterations of ALS.</Description>
			</Parameters>
			<Parameters>
				<Name>Lambda</Name>
				<Value>0.01</Value>
				<Description>Regularization parameter in ALS.</Description>
			</Parameters>
			<Parameters>
				<Name>Blocks</Name>
				<Value>-1</Value>
				<Description>Level of Parallelism to split computation into. Set to -1 to auto-configure.</Description>
			</Parameters>
			<Parameters>
				<Name>Alpha</Name>
				<Value>40</Value>
				<Description>Confidence parameter.</Description>
			</Parameters>
			<Parameters>
				<Name>Weights</Name>
				<Value>30,70</Value>
				<Description>Comma separated weights given to fields.</Description>
			</Parameters>
		</Algorithm>
		<Algorithm>
			<Name>STACKED_AUTOENCODERS</Name>
			<Type>Deeplearning</Type>
			<Parameters>
				<Name>Batch_Size</Name>
				<Value>100</Value>
				<Description>Batch Size determines the number of training cases considered
					for each epoch.</Description>
			</Parameters>
			<Parameters>
				<Name>Layer_Sizes</Name>
				<Value>500,500,500</Value>
				<Description>Layer Sizes determines the number of neurons of each layer.
					The first layer is the closest to the inputs and the last is the furthest
					from inputs.This is a comma-separated value.</Description>
			</Parameters>
			<Parameters>
				<Name>Activation_Type</Name>
				<Value>RectifierWithDropout</Value>
				<Description>Activation type is the function used to activate neurons
					when inputs given (i.e. f(W.x + b) where W,b and x are weights and bias and inputs
					respectively). The possible values are, Rectifier, RectifierWithDropout, Tanh, TanhWithDropout,
					Maxout, MaxoutWithDropout (case sensitive)
				</Description>
			</Parameters>
			<Parameters>
				<Name>Epochs</Name>
				<Value>10</Value>
				<Description>Epochs define the number of iterations the network is trained for.
					It is important to have a suitable number of epochs, as a high number can lead
					to over-fitting.</Description>
			</Parameters>
		</Algorithm>
	</Algorithms>
</MachineLearner>
